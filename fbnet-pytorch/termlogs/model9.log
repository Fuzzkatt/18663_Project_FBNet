[33mIP:142 [0m[32m[0423 04:12:41 @model.py:312][0m Start to train w for epoch 0
[33mIP:142 [0m[32m[0423 04:13:39 @model.py:297][0m Epoch[0] Batch[100] Speed: 443.839154 samples/sec loss: 2.72146 acc: 0.14252 ce: 2.24000 lat: 3.85278 ener: 18.69676
[33mIP:142 [0m[32m[0423 04:14:32 @model.py:312][0m Start to train w for epoch 1
[33mIP:142 [0m[32m[0423 04:15:30 @model.py:297][0m Epoch[1] Batch[100] Speed: 231.097524 samples/sec loss: 2.50750 acc: 0.21374 ce: 2.02603 lat: 3.85270 ener: 18.69814
[33mIP:142 [0m[32m[0423 04:16:23 @model.py:312][0m Start to train w for epoch 2
[33mIP:142 [0m[32m[0423 04:17:21 @model.py:297][0m Epoch[2] Batch[100] Speed: 230.914065 samples/sec loss: 2.41957 acc: 0.25007 ce: 1.93810 lat: 3.85267 ener: 18.69858
[33mIP:142 [0m[32m[0423 04:18:14 @model.py:312][0m Start to train w for epoch 3
[33mIP:142 [0m[32m[0423 04:19:11 @model.py:297][0m Epoch[3] Batch[100] Speed: 231.937909 samples/sec loss: 2.36740 acc: 0.27221 ce: 1.88592 lat: 3.85271 ener: 18.69930
[33mIP:142 [0m[32m[0423 04:20:04 @model.py:312][0m Start to train w for epoch 4
[33mIP:142 [0m[32m[0423 04:21:01 @model.py:297][0m Epoch[4] Batch[100] Speed: 232.087234 samples/sec loss: 2.33228 acc: 0.28687 ce: 1.85080 lat: 3.85270 ener: 18.69898
[33mIP:142 [0m[32m[0423 04:21:55 @model.py:312][0m Start to train w for epoch 5
[33mIP:142 [0m[32m[0423 04:22:52 @model.py:297][0m Epoch[5] Batch[100] Speed: 231.931368 samples/sec loss: 2.30521 acc: 0.29861 ce: 1.82373 lat: 3.85271 ener: 18.69907
[33mIP:142 [0m[32m[0423 04:23:45 @model.py:312][0m Start to train w for epoch 6
[33mIP:142 [0m[32m[0423 04:24:42 @model.py:297][0m Epoch[6] Batch[100] Speed: 232.007467 samples/sec loss: 2.26363 acc: 0.31636 ce: 1.78216 lat: 3.85269 ener: 18.69891
[33mIP:142 [0m[32m[0423 04:25:35 @model.py:312][0m Start to train w for epoch 7
[33mIP:142 [0m[32m[0423 04:26:32 @model.py:297][0m Epoch[7] Batch[100] Speed: 232.015490 samples/sec loss: 2.22512 acc: 0.33329 ce: 1.74364 lat: 3.85268 ener: 18.69915
[33mIP:142 [0m[32m[0423 04:27:25 @model.py:312][0m Start to train w for epoch 8
[33mIP:142 [0m[32m[0423 04:28:23 @model.py:297][0m Epoch[8] Batch[100] Speed: 231.963478 samples/sec loss: 2.19092 acc: 0.34828 ce: 1.70944 lat: 3.85269 ener: 18.69928
[33mIP:142 [0m[32m[0423 04:29:16 @model.py:312][0m Start to train w for epoch 9
[33mIP:142 [0m[32m[0423 04:30:13 @model.py:297][0m Epoch[9] Batch[100] Speed: 231.273981 samples/sec loss: 2.15640 acc: 0.36340 ce: 1.67492 lat: 3.85271 ener: 18.69941
[33mIP:142 [0m[32m[0423 04:31:06 @model.py:323][0m Start to train theta for epoch 10
[33mIP:142 [0m[32m[0423 04:32:00 @model.py:297][0m Epoch[10] Batch[100] Speed: 478.899707 samples/sec loss: 2.12044 acc: 0.37850 ce: 1.63901 lat: 3.85261 ener: 18.69337
[33mIP:142 [0m[32m[0423 04:32:50 @model.py:267][0m Change temperature from 5.00000 to 4.78000
[33mIP:142 [0m[32m[0423 04:32:50 @model.py:331][0m Start to train w for epoch 10
[33mIP:142 [0m[32m[0423 04:33:47 @model.py:297][0m Epoch[10] Batch[100] Speed: 238.833316 samples/sec loss: 2.08817 acc: 0.39171 ce: 1.60697 lat: 3.85217 ener: 18.66433
[33mIP:142 [0m[32m[0423 04:34:40 @model.py:323][0m Start to train theta for epoch 11
[33mIP:142 [0m[32m[0423 04:35:34 @model.py:297][0m Epoch[11] Batch[100] Speed: 240.359437 samples/sec loss: 2.05498 acc: 0.40556 ce: 1.57397 lat: 3.85182 ener: 18.63893
[33mIP:142 [0m[32m[0423 04:36:23 @model.py:267][0m Change temperature from 4.78000 to 4.56968
[33mIP:142 [0m[32m[0423 04:36:23 @model.py:331][0m Start to train w for epoch 11
[33mIP:142 [0m[32m[0423 04:37:21 @model.py:297][0m Epoch[11] Batch[100] Speed: 239.521463 samples/sec loss: 2.02781 acc: 0.41691 ce: 1.54694 lat: 3.85171 ener: 18.62047
[33mIP:142 [0m[32m[0423 04:38:14 @model.py:323][0m Start to train theta for epoch 12
[33mIP:142 [0m[32m[0423 04:39:07 @model.py:297][0m Epoch[12] Batch[100] Speed: 240.234732 samples/sec loss: 2.00361 acc: 0.42699 ce: 1.52288 lat: 3.85188 ener: 18.60374
[33mIP:142 [0m[32m[0423 04:39:57 @model.py:267][0m Change temperature from 4.56968 to 4.36861
[33mIP:142 [0m[32m[0423 04:39:57 @model.py:331][0m Start to train w for epoch 12
[33mIP:142 [0m[32m[0423 04:40:54 @model.py:297][0m Epoch[12] Batch[100] Speed: 239.479888 samples/sec loss: 1.98172 acc: 0.43622 ce: 1.50107 lat: 3.85300 ener: 18.59225
[33mIP:142 [0m[32m[0423 04:41:47 @model.py:323][0m Start to train theta for epoch 13
[33mIP:142 [0m[32m[0423 04:42:41 @model.py:297][0m Epoch[13] Batch[100] Speed: 240.217809 samples/sec loss: 1.96127 acc: 0.44480 ce: 1.48072 lat: 3.85385 ener: 18.57972
[33mIP:142 [0m[32m[0423 04:43:30 @model.py:267][0m Change temperature from 4.36861 to 4.17640
[33mIP:142 [0m[32m[0423 04:43:30 @model.py:331][0m Start to train w for epoch 13
[33mIP:142 [0m[32m[0423 04:44:28 @model.py:297][0m Epoch[13] Batch[100] Speed: 238.723597 samples/sec loss: 1.94255 acc: 0.45257 ce: 1.46213 lat: 3.85398 ener: 18.56268
[33mIP:142 [0m[32m[0423 04:45:21 @model.py:323][0m Start to train theta for epoch 14
[33mIP:142 [0m[32m[0423 04:46:15 @model.py:297][0m Epoch[14] Batch[100] Speed: 239.804663 samples/sec loss: 1.92416 acc: 0.46031 ce: 1.44392 lat: 3.85373 ener: 18.53999
[33mIP:142 [0m[32m[0423 04:47:04 @model.py:267][0m Change temperature from 4.17640 to 3.99263
[33mIP:142 [0m[32m[0423 04:47:04 @model.py:331][0m Start to train w for epoch 14
[33mIP:142 [0m[32m[0423 04:48:02 @model.py:297][0m Epoch[14] Batch[100] Speed: 239.130830 samples/sec loss: 1.90669 acc: 0.46759 ce: 1.42666 lat: 3.85314 ener: 18.51350
[33mIP:142 [0m[32m[0423 04:48:55 @model.py:323][0m Start to train theta for epoch 15
[33mIP:142 [0m[32m[0423 04:49:48 @model.py:297][0m Epoch[15] Batch[100] Speed: 239.690005 samples/sec loss: 1.88956 acc: 0.47467 ce: 1.40971 lat: 3.85238 ener: 18.49039
[33mIP:142 [0m[32m[0423 04:50:38 @model.py:267][0m Change temperature from 3.99263 to 3.81696
[33mIP:142 [0m[32m[0423 04:50:38 @model.py:331][0m Start to train w for epoch 15
[33mIP:142 [0m[32m[0423 04:51:36 @model.py:297][0m Epoch[15] Batch[100] Speed: 238.433444 samples/sec loss: 1.87300 acc: 0.48137 ce: 1.39328 lat: 3.85136 ener: 18.47411
[33mIP:142 [0m[32m[0423 04:52:29 @model.py:323][0m Start to train theta for epoch 16
[33mIP:142 [0m[32m[0423 04:53:22 @model.py:297][0m Epoch[16] Batch[100] Speed: 239.938991 samples/sec loss: 1.85661 acc: 0.48793 ce: 1.37700 lat: 3.85050 ener: 18.46003
[33mIP:142 [0m[32m[0423 04:54:12 @model.py:267][0m Change temperature from 3.81696 to 3.64901
[33mIP:142 [0m[32m[0423 04:54:12 @model.py:331][0m Start to train w for epoch 16
[33mIP:142 [0m[32m[0423 04:55:09 @model.py:297][0m Epoch[16] Batch[100] Speed: 239.400559 samples/sec loss: 1.84119 acc: 0.49427 ce: 1.36167 lat: 3.85002 ener: 18.44791
[33mIP:142 [0m[32m[0423 04:56:02 @model.py:323][0m Start to train theta for epoch 17
[33mIP:142 [0m[32m[0423 04:56:56 @model.py:297][0m Epoch[17] Batch[100] Speed: 240.595600 samples/sec loss: 1.82517 acc: 0.50065 ce: 1.34577 lat: 3.84955 ener: 18.43294
[33mIP:142 [0m[32m[0423 04:57:46 @model.py:267][0m Change temperature from 3.64901 to 3.48846
[33mIP:142 [0m[32m[0423 04:57:46 @model.py:331][0m Start to train w for epoch 17
[33mIP:142 [0m[32m[0423 04:58:43 @model.py:297][0m Epoch[17] Batch[100] Speed: 239.689391 samples/sec loss: 1.81011 acc: 0.50663 ce: 1.33085 lat: 3.84933 ener: 18.41480
[33mIP:142 [0m[32m[0423 04:59:36 @model.py:323][0m Start to train theta for epoch 18
[33mIP:142 [0m[32m[0423 05:00:29 @model.py:297][0m Epoch[18] Batch[100] Speed: 240.652985 samples/sec loss: 1.79510 acc: 0.51260 ce: 1.31597 lat: 3.84910 ener: 18.39808
[33mIP:142 [0m[32m[0423 05:01:19 @model.py:267][0m Change temperature from 3.48846 to 3.33496
[33mIP:142 [0m[32m[0423 05:01:19 @model.py:331][0m Start to train w for epoch 18
[33mIP:142 [0m[32m[0423 05:02:16 @model.py:297][0m Epoch[18] Batch[100] Speed: 238.865288 samples/sec loss: 1.78114 acc: 0.51812 ce: 1.30211 lat: 3.84895 ener: 18.38526
[33mIP:142 [0m[32m[0423 05:03:09 @model.py:323][0m Start to train theta for epoch 19
[33mIP:142 [0m[32m[0423 05:04:03 @model.py:297][0m Epoch[19] Batch[100] Speed: 239.855023 samples/sec loss: 1.76929 acc: 0.52286 ce: 1.29036 lat: 3.84891 ener: 18.37327
[33mIP:142 [0m[32m[0423 05:04:53 @model.py:267][0m Change temperature from 3.33496 to 3.18822
[33mIP:142 [0m[32m[0423 05:04:53 @model.py:331][0m Start to train w for epoch 19
[33mIP:142 [0m[32m[0423 05:05:50 @model.py:297][0m Epoch[19] Batch[100] Speed: 239.561930 samples/sec loss: 1.75866 acc: 0.52707 ce: 1.27981 lat: 3.84918 ener: 18.36231
[33mIP:142 [0m[32m[0423 05:06:43 @model.py:323][0m Start to train theta for epoch 20
[33mIP:142 [0m[32m[0423 05:07:36 @model.py:297][0m Epoch[20] Batch[100] Speed: 240.389759 samples/sec loss: 1.74882 acc: 0.53100 ce: 1.27010 lat: 3.84910 ener: 18.34594
[33mIP:142 [0m[32m[0423 05:08:26 @model.py:267][0m Change temperature from 3.18822 to 3.04794
[33mIP:142 [0m[32m[0423 05:08:26 @model.py:331][0m Start to train w for epoch 20
[33mIP:142 [0m[32m[0423 05:09:23 @model.py:297][0m Epoch[20] Batch[100] Speed: 239.212973 samples/sec loss: 1.73965 acc: 0.53463 ce: 1.26113 lat: 3.84867 ener: 18.32137
[33mIP:142 [0m[32m[0423 05:10:16 @model.py:323][0m Start to train theta for epoch 21
[33mIP:142 [0m[32m[0423 05:11:10 @model.py:297][0m Epoch[21] Batch[100] Speed: 240.703532 samples/sec loss: 1.73045 acc: 0.53832 ce: 1.25209 lat: 3.84848 ener: 18.30045
[33mIP:142 [0m[32m[0423 05:11:59 @model.py:267][0m Change temperature from 3.04794 to 2.91383
[33mIP:142 [0m[32m[0423 05:11:59 @model.py:331][0m Start to train w for epoch 21
[33mIP:142 [0m[32m[0423 05:12:57 @model.py:297][0m Epoch[21] Batch[100] Speed: 239.535400 samples/sec loss: 1.72143 acc: 0.54197 ce: 1.24317 lat: 3.84883 ener: 18.28840
[33mIP:142 [0m[32m[0423 05:13:50 @model.py:323][0m Start to train theta for epoch 22
[33mIP:142 [0m[32m[0423 05:14:43 @model.py:297][0m Epoch[22] Batch[100] Speed: 240.700441 samples/sec loss: 1.71217 acc: 0.54563 ce: 1.23400 lat: 3.84925 ener: 18.27685
[33mIP:142 [0m[32m[0423 05:15:33 @model.py:267][0m Change temperature from 2.91383 to 2.78562
[33mIP:142 [0m[32m[0423 05:15:33 @model.py:331][0m Start to train w for epoch 22
[33mIP:142 [0m[32m[0423 05:16:30 @model.py:297][0m Epoch[22] Batch[100] Speed: 239.207516 samples/sec loss: 1.70362 acc: 0.54910 ce: 1.22553 lat: 3.84985 ener: 18.26629
[33mIP:142 [0m[32m[0423 05:17:23 @model.py:323][0m Start to train theta for epoch 23
[33mIP:142 [0m[32m[0423 05:18:16 @model.py:297][0m Epoch[23] Batch[100] Speed: 240.136970 samples/sec loss: 1.69488 acc: 0.55257 ce: 1.21688 lat: 3.85032 ener: 18.25460
[33mIP:142 [0m[32m[0423 05:19:06 @model.py:267][0m Change temperature from 2.78562 to 2.66306
[33mIP:142 [0m[32m[0423 05:19:06 @model.py:331][0m Start to train w for epoch 23
[33mIP:142 [0m[32m[0423 05:20:03 @model.py:297][0m Epoch[23] Batch[100] Speed: 239.849896 samples/sec loss: 1.68663 acc: 0.55585 ce: 1.20874 lat: 3.85066 ener: 18.24119
[33mIP:142 [0m[32m[0423 05:20:56 @model.py:323][0m Start to train theta for epoch 24
[33mIP:142 [0m[32m[0423 05:21:50 @model.py:297][0m Epoch[24] Batch[100] Speed: 240.773498 samples/sec loss: 1.67784 acc: 0.55925 ce: 1.20006 lat: 3.85104 ener: 18.22684
[33mIP:142 [0m[32m[0423 05:22:39 @model.py:267][0m Change temperature from 2.66306 to 2.54588
[33mIP:142 [0m[32m[0423 05:22:39 @model.py:331][0m Start to train w for epoch 24
[33mIP:142 [0m[32m[0423 05:23:36 @model.py:297][0m Epoch[24] Batch[100] Speed: 239.812886 samples/sec loss: 1.66921 acc: 0.56260 ce: 1.19158 lat: 3.85136 ener: 18.20804
[33mIP:142 [0m[32m[0423 05:24:29 @model.py:323][0m Start to train theta for epoch 25
[33mIP:142 [0m[32m[0423 05:25:23 @model.py:297][0m Epoch[25] Batch[100] Speed: 240.320363 samples/sec loss: 1.66082 acc: 0.56586 ce: 1.18333 lat: 3.85168 ener: 18.19081
[33mIP:142 [0m[32m[0423 05:26:13 @model.py:267][0m Change temperature from 2.54588 to 2.43386
[33mIP:142 [0m[32m[0423 05:26:13 @model.py:331][0m Start to train w for epoch 25
[33mIP:142 [0m[32m[0423 05:27:10 @model.py:297][0m Epoch[25] Batch[100] Speed: 239.082627 samples/sec loss: 1.65258 acc: 0.56909 ce: 1.17517 lat: 3.85231 ener: 18.18088
[33mIP:142 [0m[32m[0423 05:28:03 @model.py:323][0m Start to train theta for epoch 26
[33mIP:142 [0m[32m[0423 05:28:57 @model.py:297][0m Epoch[26] Batch[100] Speed: 239.768247 samples/sec loss: 1.64450 acc: 0.57219 ce: 1.16717 lat: 3.85296 ener: 18.17011
[33mIP:142 [0m[32m[0423 05:29:47 @model.py:267][0m Change temperature from 2.43386 to 2.32677
[33mIP:142 [0m[32m[0423 05:29:47 @model.py:331][0m Start to train w for epoch 26
[33mIP:142 [0m[32m[0423 05:30:44 @model.py:297][0m Epoch[26] Batch[100] Speed: 239.244311 samples/sec loss: 1.63651 acc: 0.57528 ce: 1.15928 lat: 3.85377 ener: 18.15792
[33mIP:142 [0m[32m[0423 05:31:37 @model.py:323][0m Start to train theta for epoch 27
[33mIP:142 [0m[32m[0423 05:32:30 @model.py:297][0m Epoch[27] Batch[100] Speed: 240.612991 samples/sec loss: 1.62852 acc: 0.57835 ce: 1.15140 lat: 3.85448 ener: 18.14425
[33mIP:142 [0m[32m[0423 05:33:20 @model.py:267][0m Change temperature from 2.32677 to 2.22440
[33mIP:142 [0m[32m[0423 05:33:20 @model.py:331][0m Start to train w for epoch 27
[33mIP:142 [0m[32m[0423 05:34:17 @model.py:297][0m Epoch[27] Batch[100] Speed: 238.507198 samples/sec loss: 1.62077 acc: 0.58134 ce: 1.14377 lat: 3.85499 ener: 18.12846
[33mIP:142 [0m[32m[0423 05:35:11 @model.py:323][0m Start to train theta for epoch 28
[33mIP:142 [0m[32m[0423 05:36:04 @model.py:297][0m Epoch[28] Batch[100] Speed: 240.034026 samples/sec loss: 1.61296 acc: 0.58432 ce: 1.13610 lat: 3.85546 ener: 18.11173
[33mIP:142 [0m[32m[0423 05:36:54 @model.py:267][0m Change temperature from 2.22440 to 2.12652
[33mIP:142 [0m[32m[0423 05:36:54 @model.py:331][0m Start to train w for epoch 28
[33mIP:142 [0m[32m[0423 05:37:51 @model.py:297][0m Epoch[28] Batch[100] Speed: 239.553263 samples/sec loss: 1.60543 acc: 0.58723 ce: 1.12874 lat: 3.85580 ener: 18.09118
[33mIP:142 [0m[32m[0423 05:38:44 @model.py:323][0m Start to train theta for epoch 29
[33mIP:142 [0m[32m[0423 05:39:37 @model.py:297][0m Epoch[29] Batch[100] Speed: 240.250579 samples/sec loss: 1.59785 acc: 0.59012 ce: 1.12132 lat: 3.85611 ener: 18.07027
[33mIP:142 [0m[32m[0423 05:40:27 @model.py:267][0m Change temperature from 2.12652 to 2.03296
[33mIP:142 [0m[32m[0423 05:40:27 @model.py:331][0m Start to train w for epoch 29
[33mIP:142 [0m[32m[0423 05:41:25 @model.py:297][0m Epoch[29] Batch[100] Speed: 239.196874 samples/sec loss: 1.59120 acc: 0.59268 ce: 1.11484 lat: 3.85641 ener: 18.04939
[33mIP:142 [0m[32m[0423 05:42:18 @model.py:323][0m Start to train theta for epoch 30
[33mIP:142 [0m[32m[0423 05:43:11 @model.py:297][0m Epoch[30] Batch[100] Speed: 240.132887 samples/sec loss: 1.58683 acc: 0.59437 ce: 1.11067 lat: 3.85637 ener: 18.02434
[33mIP:142 [0m[32m[0423 05:44:01 @model.py:267][0m Change temperature from 2.03296 to 1.94351
[33mIP:142 [0m[32m[0423 05:44:01 @model.py:331][0m Start to train w for epoch 30
[33mIP:142 [0m[32m[0423 05:44:58 @model.py:297][0m Epoch[30] Batch[100] Speed: 238.677969 samples/sec loss: 1.58236 acc: 0.59607 ce: 1.10644 lat: 3.85600 ener: 17.99448
[33mIP:142 [0m[32m[0423 05:45:52 @model.py:323][0m Start to train theta for epoch 31
[33mIP:142 [0m[32m[0423 05:46:45 @model.py:297][0m Epoch[31] Batch[100] Speed: 239.904226 samples/sec loss: 1.57787 acc: 0.59783 ce: 1.10217 lat: 3.85596 ener: 17.96720
[33mIP:142 [0m[32m[0423 05:47:35 @model.py:267][0m Change temperature from 1.94351 to 1.85799
[33mIP:142 [0m[32m[0423 05:47:35 @model.py:331][0m Start to train w for epoch 31
[33mIP:142 [0m[32m[0423 05:48:32 @model.py:297][0m Epoch[31] Batch[100] Speed: 239.231390 samples/sec loss: 1.57347 acc: 0.59956 ce: 1.09794 lat: 3.85665 ener: 17.94693
[33mIP:142 [0m[32m[0423 05:49:25 @model.py:323][0m Start to train theta for epoch 32
[33mIP:142 [0m[32m[0423 05:50:19 @model.py:297][0m Epoch[32] Batch[100] Speed: 240.438254 samples/sec loss: 1.56867 acc: 0.60143 ce: 1.09330 lat: 3.85725 ener: 17.92728
[33mIP:142 [0m[32m[0423 05:51:08 @model.py:267][0m Change temperature from 1.85799 to 1.77624
[33mIP:142 [0m[32m[0423 05:51:08 @model.py:331][0m Start to train w for epoch 32
[33mIP:142 [0m[32m[0423 05:52:05 @model.py:297][0m Epoch[32] Batch[100] Speed: 239.855655 samples/sec loss: 1.56408 acc: 0.60322 ce: 1.08889 lat: 3.85767 ener: 17.90512
[33mIP:142 [0m[32m[0423 05:52:58 @model.py:323][0m Start to train theta for epoch 33
[33mIP:142 [0m[32m[0423 05:53:52 @model.py:297][0m Epoch[33] Batch[100] Speed: 240.403706 samples/sec loss: 1.55952 acc: 0.60501 ce: 1.08453 lat: 3.85806 ener: 17.88043
[33mIP:142 [0m[32m[0423 05:54:42 @model.py:267][0m Change temperature from 1.77624 to 1.69808
[33mIP:142 [0m[32m[0423 05:54:42 @model.py:331][0m Start to train w for epoch 33
[33mIP:142 [0m[32m[0423 05:55:39 @model.py:297][0m Epoch[33] Batch[100] Speed: 239.168220 samples/sec loss: 1.55507 acc: 0.60672 ce: 1.08033 lat: 3.85838 ener: 17.84926
[33mIP:142 [0m[32m[0423 05:56:32 @model.py:323][0m Start to train theta for epoch 34
[33mIP:142 [0m[32m[0423 05:57:25 @model.py:297][0m Epoch[34] Batch[100] Speed: 240.425626 samples/sec loss: 1.55049 acc: 0.60847 ce: 1.07602 lat: 3.85850 ener: 17.81740
[33mIP:142 [0m[32m[0423 05:58:15 @model.py:267][0m Change temperature from 1.69808 to 1.62337
[33mIP:142 [0m[32m[0423 05:58:15 @model.py:331][0m Start to train w for epoch 34
[33mIP:142 [0m[32m[0423 05:59:12 @model.py:297][0m Epoch[34] Batch[100] Speed: 239.461014 samples/sec loss: 1.54609 acc: 0.61017 ce: 1.07185 lat: 3.85851 ener: 17.78934
[33mIP:142 [0m[32m[0423 06:00:05 @model.py:323][0m Start to train theta for epoch 35
[33mIP:142 [0m[32m[0423 06:00:59 @model.py:297][0m Epoch[35] Batch[100] Speed: 239.941576 samples/sec loss: 1.54170 acc: 0.61186 ce: 1.06768 lat: 3.85860 ener: 17.76267
[33mIP:142 [0m[32m[0423 06:01:49 @model.py:267][0m Change temperature from 1.62337 to 1.55194
[33mIP:142 [0m[32m[0423 06:01:49 @model.py:331][0m Start to train w for epoch 35
[33mIP:142 [0m[32m[0423 06:02:46 @model.py:297][0m Epoch[35] Batch[100] Speed: 239.555950 samples/sec loss: 1.53735 acc: 0.61356 ce: 1.06352 lat: 3.85905 ener: 17.73947
[33mIP:142 [0m[32m[0423 06:03:39 @model.py:323][0m Start to train theta for epoch 36
[33mIP:142 [0m[32m[0423 06:04:32 @model.py:297][0m Epoch[36] Batch[100] Speed: 240.092491 samples/sec loss: 1.53312 acc: 0.61520 ce: 1.05948 lat: 3.85942 ener: 17.71582
[33mIP:142 [0m[32m[0423 06:05:22 @model.py:267][0m Change temperature from 1.55194 to 1.48366
[33mIP:142 [0m[32m[0423 06:05:22 @model.py:331][0m Start to train w for epoch 36
[33mIP:142 [0m[32m[0423 06:06:19 @model.py:297][0m Epoch[36] Batch[100] Speed: 239.567617 samples/sec loss: 1.52885 acc: 0.61686 ce: 1.05541 lat: 3.85970 ener: 17.69108
[33mIP:142 [0m[32m[0423 06:07:12 @model.py:323][0m Start to train theta for epoch 37
[33mIP:142 [0m[32m[0423 06:08:06 @model.py:297][0m Epoch[37] Batch[100] Speed: 240.611925 samples/sec loss: 1.52432 acc: 0.61857 ce: 1.05109 lat: 3.86007 ener: 17.66578
[33mIP:142 [0m[32m[0423 06:08:55 @model.py:267][0m Change temperature from 1.48366 to 1.41837
[33mIP:142 [0m[32m[0423 06:08:55 @model.py:331][0m Start to train w for epoch 37
[33mIP:142 [0m[32m[0423 06:09:53 @model.py:297][0m Epoch[37] Batch[100] Speed: 239.350096 samples/sec loss: 1.51970 acc: 0.62032 ce: 1.04671 lat: 3.86078 ener: 17.63691
[33mIP:142 [0m[32m[0423 06:10:46 @model.py:323][0m Start to train theta for epoch 38
[33mIP:142 [0m[32m[0423 06:11:39 @model.py:297][0m Epoch[38] Batch[100] Speed: 239.970200 samples/sec loss: 1.51493 acc: 0.62208 ce: 1.04220 lat: 3.86147 ener: 17.60728
[33mIP:142 [0m[32m[0423 06:12:29 @model.py:267][0m Change temperature from 1.41837 to 1.35597
[33mIP:142 [0m[32m[0423 06:12:29 @model.py:331][0m Start to train w for epoch 38
[33mIP:142 [0m[32m[0423 06:13:26 @model.py:297][0m Epoch[38] Batch[100] Speed: 239.494981 samples/sec loss: 1.51017 acc: 0.62388 ce: 1.03772 lat: 3.86174 ener: 17.57264
[33mIP:142 [0m[32m[0423 06:14:19 @model.py:323][0m Start to train theta for epoch 39
[33mIP:142 [0m[32m[0423 06:15:13 @model.py:297][0m Epoch[39] Batch[100] Speed: 240.508342 samples/sec loss: 1.50546 acc: 0.62557 ce: 1.03333 lat: 3.86172 ener: 17.53553
[33mIP:142 [0m[32m[0423 06:16:02 @model.py:267][0m Change temperature from 1.35597 to 1.29630
[33mIP:142 [0m[32m[0423 06:16:02 @model.py:331][0m Start to train w for epoch 39
[33mIP:142 [0m[32m[0423 06:17:00 @model.py:297][0m Epoch[39] Batch[100] Speed: 239.267971 samples/sec loss: 1.50072 acc: 0.62729 ce: 1.02896 lat: 3.86102 ener: 17.49158
[33mIP:142 [0m[32m[0423 06:17:53 @model.py:323][0m Start to train theta for epoch 40
[33mIP:142 [0m[32m[0423 06:18:46 @model.py:297][0m Epoch[40] Batch[100] Speed: 240.273970 samples/sec loss: 1.49592 acc: 0.62903 ce: 1.02455 lat: 3.86025 ener: 17.44668
[33mIP:142 [0m[32m[0423 06:19:36 @model.py:267][0m Change temperature from 1.29630 to 1.23927
[33mIP:142 [0m[32m[0423 06:19:36 @model.py:331][0m Start to train w for epoch 40
[33mIP:142 [0m[32m[0423 06:20:33 @model.py:297][0m Epoch[40] Batch[100] Speed: 238.986594 samples/sec loss: 1.49120 acc: 0.63072 ce: 1.02025 lat: 3.85940 ener: 17.39763
[33mIP:142 [0m[32m[0423 06:21:27 @model.py:323][0m Start to train theta for epoch 41
[33mIP:142 [0m[32m[0423 06:22:20 @model.py:297][0m Epoch[41] Batch[100] Speed: 239.613705 samples/sec loss: 1.48640 acc: 0.63242 ce: 1.01588 lat: 3.85866 ener: 17.34944
[33mIP:142 [0m[32m[0423 06:23:10 @model.py:267][0m Change temperature from 1.23927 to 1.18474
[33mIP:142 [0m[32m[0423 06:23:10 @model.py:331][0m Start to train w for epoch 41
[33mIP:142 [0m[32m[0423 06:24:07 @model.py:297][0m Epoch[41] Batch[100] Speed: 239.027040 samples/sec loss: 1.48172 acc: 0.63407 ce: 1.01160 lat: 3.85814 ener: 17.30290
[33mIP:142 [0m[32m[0423 06:25:00 @model.py:323][0m Start to train theta for epoch 42
[33mIP:142 [0m[32m[0423 06:25:54 @model.py:297][0m Epoch[42] Batch[100] Speed: 240.372467 samples/sec loss: 1.47683 acc: 0.63581 ce: 1.00714 lat: 3.85749 ener: 17.25435
[33mIP:142 [0m[32m[0423 06:26:43 @model.py:267][0m Change temperature from 1.18474 to 1.13261
[33mIP:142 [0m[32m[0423 06:26:43 @model.py:331][0m Start to train w for epoch 42
[33mIP:142 [0m[32m[0423 06:27:41 @model.py:297][0m Epoch[42] Batch[100] Speed: 239.688570 samples/sec loss: 1.47192 acc: 0.63751 ce: 1.00272 lat: 3.85641 ener: 17.19899
[33mIP:142 [0m[32m[0423 06:28:34 @model.py:323][0m Start to train theta for epoch 43
[33mIP:142 [0m[32m[0423 06:29:27 @model.py:297][0m Epoch[43] Batch[100] Speed: 240.727153 samples/sec loss: 1.46708 acc: 0.63918 ce: 0.99838 lat: 3.85530 ener: 17.14262
[33mIP:142 [0m[32m[0423 06:30:17 @model.py:267][0m Change temperature from 1.13261 to 1.08278
[33mIP:142 [0m[32m[0423 06:30:17 @model.py:331][0m Start to train w for epoch 43
[33mIP:142 [0m[32m[0423 06:31:14 @model.py:297][0m Epoch[43] Batch[100] Speed: 239.869919 samples/sec loss: 1.46218 acc: 0.64086 ce: 0.99403 lat: 3.85417 ener: 17.08312
[33mIP:142 [0m[32m[0423 06:32:07 @model.py:323][0m Start to train theta for epoch 44
[33mIP:142 [0m[32m[0423 06:33:00 @model.py:297][0m Epoch[44] Batch[100] Speed: 240.745854 samples/sec loss: 1.45730 acc: 0.64252 ce: 0.98970 lat: 3.85289 ener: 17.02189
[33mIP:142 [0m[32m[0423 06:33:50 @model.py:267][0m Change temperature from 1.08278 to 1.03513
[33mIP:142 [0m[32m[0423 06:33:50 @model.py:331][0m Start to train w for epoch 44
[33mIP:142 [0m[32m[0423 06:34:47 @model.py:297][0m Epoch[44] Batch[100] Speed: 239.288462 samples/sec loss: 1.45250 acc: 0.64412 ce: 0.98550 lat: 3.85129 ener: 16.95681
[33mIP:142 [0m[32m[0423 06:35:40 @model.py:323][0m Start to train theta for epoch 45
[33mIP:142 [0m[32m[0423 06:36:33 @model.py:297][0m Epoch[45] Batch[100] Speed: 240.633183 samples/sec loss: 1.44771 acc: 0.64572 ce: 0.98132 lat: 3.84964 ener: 16.89186
[33mIP:142 [0m[32m[0423 06:37:23 @model.py:267][0m Change temperature from 1.03513 to 0.98959
[33mIP:142 [0m[32m[0423 06:37:23 @model.py:331][0m Start to train w for epoch 45
[33mIP:142 [0m[32m[0423 06:38:20 @model.py:297][0m Epoch[45] Batch[100] Speed: 239.039944 samples/sec loss: 1.44371 acc: 0.64706 ce: 0.97792 lat: 3.84794 ener: 16.82677
[33mIP:142 [0m[32m[0423 06:39:14 @model.py:323][0m Start to train theta for epoch 46
[33mIP:142 [0m[32m[0423 06:40:07 @model.py:297][0m Epoch[46] Batch[100] Speed: 239.725158 samples/sec loss: 1.44158 acc: 0.64775 ce: 0.97641 lat: 3.84594 ener: 16.75993
[33mIP:142 [0m[32m[0423 06:40:57 @model.py:267][0m Change temperature from 0.98959 to 0.94605
[33mIP:142 [0m[32m[0423 06:40:57 @model.py:331][0m Start to train w for epoch 46
[33mIP:142 [0m[32m[0423 06:41:54 @model.py:297][0m Epoch[46] Batch[100] Speed: 239.083323 samples/sec loss: 1.43940 acc: 0.64845 ce: 0.97486 lat: 3.84354 ener: 16.69365
[33mIP:142 [0m[32m[0423 06:42:47 @model.py:323][0m Start to train theta for epoch 47
[33mIP:142 [0m[32m[0423 06:43:41 @model.py:297][0m Epoch[47] Batch[100] Speed: 240.077803 samples/sec loss: 1.43727 acc: 0.64915 ce: 0.97333 lat: 3.84117 ener: 16.62968
[33mIP:142 [0m[32m[0423 06:44:31 @model.py:267][0m Change temperature from 0.94605 to 0.90442
[33mIP:142 [0m[32m[0423 06:44:31 @model.py:331][0m Start to train w for epoch 47
[33mIP:142 [0m[32m[0423 06:45:28 @model.py:297][0m Epoch[47] Batch[100] Speed: 239.463767 samples/sec loss: 1.43527 acc: 0.64981 ce: 0.97188 lat: 3.83900 ener: 16.56982
[33mIP:142 [0m[32m[0423 06:46:21 @model.py:323][0m Start to train theta for epoch 48
[33mIP:142 [0m[32m[0423 06:47:14 @model.py:297][0m Epoch[48] Batch[100] Speed: 240.056036 samples/sec loss: 1.43290 acc: 0.65060 ce: 0.97004 lat: 3.83701 ener: 16.51250
[33mIP:142 [0m[32m[0423 06:48:04 @model.py:267][0m Change temperature from 0.90442 to 0.86463
[33mIP:142 [0m[32m[0423 06:48:04 @model.py:331][0m Start to train w for epoch 48
[33mIP:142 [0m[32m[0423 06:49:01 @model.py:297][0m Epoch[48] Batch[100] Speed: 239.353402 samples/sec loss: 1.43031 acc: 0.65150 ce: 0.96797 lat: 3.83542 ener: 16.45684
[33mIP:142 [0m[32m[0423 06:49:54 @model.py:323][0m Start to train theta for epoch 49
[33mIP:142 [0m[32m[0423 06:50:48 @model.py:297][0m Epoch[49] Batch[100] Speed: 240.579233 samples/sec loss: 1.42786 acc: 0.65231 ce: 0.96605 lat: 3.83389 ener: 16.40073
[33mIP:142 [0m[32m[0423 06:51:37 @model.py:267][0m Change temperature from 0.86463 to 0.82658
[33mIP:142 [0m[32m[0423 06:51:37 @model.py:331][0m Start to train w for epoch 49
[33mIP:142 [0m[32m[0423 06:52:35 @model.py:297][0m Epoch[49] Batch[100] Speed: 239.506356 samples/sec loss: 1.42534 acc: 0.65313 ce: 0.96406 lat: 3.83254 ener: 16.34308
[33mIP:142 [0m[32m[0423 06:53:28 @model.py:323][0m Start to train theta for epoch 50
[33mIP:142 [0m[32m[0423 06:54:21 @model.py:297][0m Epoch[50] Batch[100] Speed: 240.519782 samples/sec loss: 1.42292 acc: 0.65398 ce: 0.96217 lat: 3.83130 ener: 16.28692
[33mIP:142 [0m[32m[0423 06:55:11 @model.py:267][0m Change temperature from 0.82658 to 0.79021
[33mIP:142 [0m[32m[0423 06:55:11 @model.py:331][0m Start to train w for epoch 50
[33mIP:142 [0m[32m[0423 06:56:08 @model.py:297][0m Epoch[50] Batch[100] Speed: 239.860142 samples/sec loss: 1.42037 acc: 0.65488 ce: 0.96009 lat: 3.83060 ener: 16.23671
[33mIP:142 [0m[32m[0423 06:57:01 @model.py:323][0m Start to train theta for epoch 51
[33mIP:142 [0m[32m[0423 06:57:54 @model.py:297][0m Epoch[51] Batch[100] Speed: 240.437173 samples/sec loss: 1.41786 acc: 0.65575 ce: 0.95804 lat: 3.82991 ener: 16.18719
[33mIP:142 [0m[32m[0423 06:58:44 @model.py:267][0m Change temperature from 0.79021 to 0.75544
[33mIP:142 [0m[32m[0423 06:58:44 @model.py:331][0m Start to train w for epoch 51
[33mIP:142 [0m[32m[0423 06:59:41 @model.py:297][0m Epoch[51] Batch[100] Speed: 239.201775 samples/sec loss: 1.41527 acc: 0.65663 ce: 0.95592 lat: 3.82916 ener: 16.13702
[33mIP:142 [0m[32m[0423 07:00:35 @model.py:323][0m Start to train theta for epoch 52
[33mIP:142 [0m[32m[0423 07:01:28 @model.py:297][0m Epoch[52] Batch[100] Speed: 240.468962 samples/sec loss: 1.41258 acc: 0.65754 ce: 0.95371 lat: 3.82841 ener: 16.08583
[33mIP:142 [0m[32m[0423 07:02:17 @model.py:267][0m Change temperature from 0.75544 to 0.72220
[33mIP:142 [0m[32m[0423 07:02:17 @model.py:331][0m Start to train w for epoch 52
[33mIP:142 [0m[32m[0423 07:03:15 @model.py:297][0m Epoch[52] Batch[100] Speed: 239.677380 samples/sec loss: 1.40970 acc: 0.65850 ce: 0.95135 lat: 3.82762 ener: 16.03143
[33mIP:142 [0m[32m[0423 07:04:08 @model.py:323][0m Start to train theta for epoch 53
[33mIP:142 [0m[32m[0423 07:05:01 @model.py:297][0m Epoch[53] Batch[100] Speed: 239.743211 samples/sec loss: 1.40687 acc: 0.65942 ce: 0.94903 lat: 3.82678 ener: 15.97704
[33mIP:142 [0m[32m[0423 07:05:51 @model.py:267][0m Change temperature from 0.72220 to 0.69043
[33mIP:142 [0m[32m[0423 07:05:51 @model.py:331][0m Start to train w for epoch 53
[33mIP:142 [0m[32m[0423 07:06:48 @model.py:297][0m Epoch[53] Batch[100] Speed: 239.558176 samples/sec loss: 1.40398 acc: 0.66037 ce: 0.94667 lat: 3.82589 ener: 15.92272
[33mIP:142 [0m[32m[0423 07:07:41 @model.py:323][0m Start to train theta for epoch 54
[33mIP:142 [0m[32m[0423 07:08:35 @model.py:297][0m Epoch[54] Batch[100] Speed: 240.560880 samples/sec loss: 1.40117 acc: 0.66131 ce: 0.94435 lat: 3.82520 ener: 15.87094
[33mIP:142 [0m[32m[0423 07:09:24 @model.py:267][0m Change temperature from 0.69043 to 0.66005
[33mIP:142 [0m[32m[0423 07:09:24 @model.py:331][0m Start to train w for epoch 54
[33mIP:142 [0m[32m[0423 07:10:22 @model.py:297][0m Epoch[54] Batch[100] Speed: 238.690719 samples/sec loss: 1.39832 acc: 0.66230 ce: 0.94192 lat: 3.82512 ener: 15.82607
[33mIP:142 [0m[32m[0423 07:11:15 @model.py:323][0m Start to train theta for epoch 55
[33mIP:142 [0m[32m[0423 07:12:09 @model.py:297][0m Epoch[55] Batch[100] Speed: 239.926679 samples/sec loss: 1.39527 acc: 0.66334 ce: 0.93930 lat: 3.82499 ener: 15.78061
[33mIP:142 [0m[32m[0423 07:12:58 @model.py:267][0m Change temperature from 0.66005 to 0.63101
[33mIP:142 [0m[32m[0423 07:12:58 @model.py:331][0m Start to train w for epoch 55
[33mIP:142 [0m[32m[0423 07:13:56 @model.py:297][0m Epoch[55] Batch[100] Speed: 238.977764 samples/sec loss: 1.39204 acc: 0.66442 ce: 0.93656 lat: 3.82453 ener: 15.72972
[33mIP:142 [0m[32m[0423 07:14:49 @model.py:323][0m Start to train theta for epoch 56
[33mIP:142 [0m[32m[0423 07:15:42 @model.py:297][0m Epoch[56] Batch[100] Speed: 239.958445 samples/sec loss: 1.38885 acc: 0.66548 ce: 0.93386 lat: 3.82406 ener: 15.67926
[33mIP:142 [0m[32m[0423 07:16:32 @model.py:267][0m Change temperature from 0.63101 to 0.60324
[33mIP:142 [0m[32m[0423 07:16:32 @model.py:331][0m Start to train w for epoch 56
[33mIP:142 [0m[32m[0423 07:17:29 @model.py:297][0m Epoch[56] Batch[100] Speed: 239.320529 samples/sec loss: 1.38571 acc: 0.66654 ce: 0.93118 lat: 3.82369 ener: 15.63129
[33mIP:142 [0m[32m[0423 07:18:22 @model.py:323][0m Start to train theta for epoch 57
[33mIP:142 [0m[32m[0423 07:19:16 @model.py:297][0m Epoch[57] Batch[100] Speed: 240.601964 samples/sec loss: 1.38251 acc: 0.66760 ce: 0.92842 lat: 3.82334 ener: 15.58426
[33mIP:142 [0m[32m[0423 07:20:06 @model.py:267][0m Change temperature from 0.60324 to 0.57670
[33mIP:142 [0m[32m[0423 07:20:06 @model.py:331][0m Start to train w for epoch 57
[33mIP:142 [0m[32m[0423 07:21:03 @model.py:297][0m Epoch[57] Batch[100] Speed: 239.101810 samples/sec loss: 1.37927 acc: 0.66867 ce: 0.92563 lat: 3.82298 ener: 15.53784
[33mIP:142 [0m[32m[0423 07:21:56 @model.py:323][0m Start to train theta for epoch 58
[33mIP:142 [0m[32m[0423 07:22:50 @model.py:297][0m Epoch[58] Batch[100] Speed: 240.005917 samples/sec loss: 1.37586 acc: 0.66981 ce: 0.92267 lat: 3.82261 ener: 15.49165
[33mIP:142 [0m[32m[0423 07:23:39 @model.py:267][0m Change temperature from 0.57670 to 0.55132
[33mIP:142 [0m[32m[0423 07:23:39 @model.py:331][0m Start to train w for epoch 58
[33mIP:142 [0m[32m[0423 07:24:36 @model.py:297][0m Epoch[58] Batch[100] Speed: 239.748905 samples/sec loss: 1.37242 acc: 0.67095 ce: 0.91968 lat: 3.82219 ener: 15.44547
[33mIP:142 [0m[32m[0423 07:25:29 @model.py:323][0m Start to train theta for epoch 59
[33mIP:142 [0m[32m[0423 07:26:23 @model.py:297][0m Epoch[59] Batch[100] Speed: 240.355144 samples/sec loss: 1.36897 acc: 0.67210 ce: 0.91666 lat: 3.82175 ener: 15.40016
[33mIP:142 [0m[32m[0423 07:27:13 @model.py:267][0m Change temperature from 0.55132 to 0.52707
[33mIP:142 [0m[32m[0423 07:27:13 @model.py:331][0m Start to train w for epoch 59
[33mIP:142 [0m[32m[0423 07:28:10 @model.py:297][0m Epoch[59] Batch[100] Speed: 238.621179 samples/sec loss: 1.36559 acc: 0.67321 ce: 0.91371 lat: 3.82105 ener: 15.35541
[33mIP:142 [0m[32m[0423 07:29:03 @model.py:323][0m Start to train theta for epoch 60
[33mIP:142 [0m[32m[0423 07:29:57 @model.py:297][0m Epoch[60] Batch[100] Speed: 239.722239 samples/sec loss: 1.36225 acc: 0.67432 ce: 0.91080 lat: 3.82038 ener: 15.31124
[33mIP:142 [0m[32m[0423 07:30:47 @model.py:267][0m Change temperature from 0.52707 to 0.50387
[33mIP:142 [0m[32m[0423 07:30:47 @model.py:331][0m Start to train w for epoch 60
[33mIP:142 [0m[32m[0423 07:31:44 @model.py:297][0m Epoch[60] Batch[100] Speed: 239.032642 samples/sec loss: 1.35883 acc: 0.67545 ce: 0.90781 lat: 3.81984 ener: 15.26774
[33mIP:142 [0m[32m[0423 07:32:37 @model.py:323][0m Start to train theta for epoch 61
[33mIP:142 [0m[32m[0423 07:33:31 @model.py:297][0m Epoch[61] Batch[100] Speed: 240.177304 samples/sec loss: 1.35529 acc: 0.67663 ce: 0.90468 lat: 3.81933 ener: 15.22478
[33mIP:142 [0m[32m[0423 07:34:21 @model.py:267][0m Change temperature from 0.50387 to 0.48170
[33mIP:142 [0m[32m[0423 07:34:21 @model.py:331][0m Start to train w for epoch 61
[33mIP:142 [0m[32m[0423 07:35:18 @model.py:297][0m Epoch[61] Batch[100] Speed: 238.983819 samples/sec loss: 1.35174 acc: 0.67780 ce: 0.90154 lat: 3.81884 ener: 15.18180
[33mIP:142 [0m[32m[0423 07:36:11 @model.py:323][0m Start to train theta for epoch 62
[33mIP:142 [0m[32m[0423 07:37:04 @model.py:297][0m Epoch[62] Batch[100] Speed: 240.201293 samples/sec loss: 1.34829 acc: 0.67893 ce: 0.89850 lat: 3.81838 ener: 15.13984
[33mIP:142 [0m[32m[0423 07:37:54 @model.py:267][0m Change temperature from 0.48170 to 0.46051
[33mIP:142 [0m[32m[0423 07:37:54 @model.py:331][0m Start to train w for epoch 62
[33mIP:142 [0m[32m[0423 07:38:51 @model.py:297][0m Epoch[62] Batch[100] Speed: 239.131903 samples/sec loss: 1.34474 acc: 0.68010 ce: 0.89534 lat: 3.81789 ener: 15.09989
[33mIP:142 [0m[32m[0423 07:39:44 @model.py:323][0m Start to train theta for epoch 63
[33mIP:142 [0m[32m[0423 07:40:38 @model.py:297][0m Epoch[63] Batch[100] Speed: 240.493302 samples/sec loss: 1.34115 acc: 0.68128 ce: 0.89213 lat: 3.81734 ener: 15.06027
[33mIP:142 [0m[32m[0423 07:41:28 @model.py:267][0m Change temperature from 0.46051 to 0.44025
[33mIP:142 [0m[32m[0423 07:41:28 @model.py:331][0m Start to train w for epoch 63
[33mIP:142 [0m[32m[0423 07:42:25 @model.py:297][0m Epoch[63] Batch[100] Speed: 239.222005 samples/sec loss: 1.33759 acc: 0.68245 ce: 0.88896 lat: 3.81661 ener: 15.02093
[33mIP:142 [0m[32m[0423 07:43:18 @model.py:323][0m Start to train theta for epoch 64
[33mIP:142 [0m[32m[0423 07:44:11 @model.py:297][0m Epoch[64] Batch[100] Speed: 240.065473 samples/sec loss: 1.33395 acc: 0.68366 ce: 0.88569 lat: 3.81585 ener: 14.98203
[33mIP:142 [0m[32m[0423 07:45:01 @model.py:267][0m Change temperature from 0.44025 to 0.42088
[33mIP:142 [0m[32m[0423 07:45:01 @model.py:331][0m Start to train w for epoch 64
[33mIP:142 [0m[32m[0423 07:45:59 @model.py:297][0m Epoch[64] Batch[100] Speed: 238.703143 samples/sec loss: 1.33030 acc: 0.68487 ce: 0.88241 lat: 3.81516 ener: 14.94403
[33mIP:142 [0m[32m[0423 07:46:52 @model.py:323][0m Start to train theta for epoch 65
[33mIP:142 [0m[32m[0423 07:47:45 @model.py:297][0m Epoch[65] Batch[100] Speed: 239.826290 samples/sec loss: 1.32669 acc: 0.68606 ce: 0.87916 lat: 3.81446 ener: 14.90619
[33mIP:142 [0m[32m[0423 07:48:35 @model.py:267][0m Change temperature from 0.42088 to 0.40236
[33mIP:142 [0m[32m[0423 07:48:35 @model.py:331][0m Start to train w for epoch 65
[33mIP:142 [0m[32m[0423 07:49:32 @model.py:297][0m Epoch[65] Batch[100] Speed: 239.969402 samples/sec loss: 1.32307 acc: 0.68725 ce: 0.87592 lat: 3.81371 ener: 14.86817
[33mIP:142 [0m[32m[0423 07:50:25 @model.py:323][0m Start to train theta for epoch 66
[33mIP:142 [0m[32m[0423 07:51:19 @model.py:297][0m Epoch[66] Batch[100] Speed: 240.540644 samples/sec loss: 1.31944 acc: 0.68846 ce: 0.87265 lat: 3.81296 ener: 14.83079
[33mIP:142 [0m[32m[0423 07:52:08 @model.py:267][0m Change temperature from 0.40236 to 0.38465
[33mIP:142 [0m[32m[0423 07:52:08 @model.py:331][0m Start to train w for epoch 66
[33mIP:142 [0m[32m[0423 07:53:05 @model.py:297][0m Epoch[66] Batch[100] Speed: 239.447980 samples/sec loss: 1.31585 acc: 0.68965 ce: 0.86942 lat: 3.81223 ener: 14.79457
[33mIP:142 [0m[32m[0423 07:53:59 @model.py:323][0m Start to train theta for epoch 67
[33mIP:142 [0m[32m[0423 07:54:52 @model.py:297][0m Epoch[67] Batch[100] Speed: 240.528003 samples/sec loss: 1.31228 acc: 0.69084 ce: 0.86620 lat: 3.81150 ener: 14.75869
[33mIP:142 [0m[32m[0423 07:55:42 @model.py:267][0m Change temperature from 0.38465 to 0.36773
[33mIP:142 [0m[32m[0423 07:55:42 @model.py:331][0m Start to train w for epoch 67
[33mIP:142 [0m[32m[0423 07:56:39 @model.py:297][0m Epoch[67] Batch[100] Speed: 239.587527 samples/sec loss: 1.30871 acc: 0.69201 ce: 0.86297 lat: 3.81082 ener: 14.72313
[33mIP:142 [0m[32m[0423 07:57:32 @model.py:323][0m Start to train theta for epoch 68
[33mIP:142 [0m[32m[0423 07:58:25 @model.py:297][0m Epoch[68] Batch[100] Speed: 240.323308 samples/sec loss: 1.30521 acc: 0.69315 ce: 0.85981 lat: 3.81017 ener: 14.68813
[33mIP:142 [0m[32m[0423 07:59:15 @model.py:267][0m Change temperature from 0.36773 to 0.35155
[33mIP:142 [0m[32m[0423 07:59:15 @model.py:331][0m Start to train w for epoch 68
[33mIP:142 [0m[32m[0423 08:00:12 @model.py:297][0m Epoch[68] Batch[100] Speed: 239.462263 samples/sec loss: 1.30171 acc: 0.69431 ce: 0.85665 lat: 3.80952 ener: 14.65339
[33mIP:142 [0m[32m[0423 08:01:05 @model.py:323][0m Start to train theta for epoch 69
[33mIP:142 [0m[32m[0423 08:01:59 @model.py:297][0m Epoch[69] Batch[100] Speed: 240.351261 samples/sec loss: 1.29887 acc: 0.69526 ce: 0.85413 lat: 3.80897 ener: 14.62010
[33mIP:142 [0m[32m[0423 08:02:49 @model.py:267][0m Change temperature from 0.35155 to 0.33608
[33mIP:142 [0m[32m[0423 08:02:49 @model.py:331][0m Start to train w for epoch 69
[33mIP:142 [0m[32m[0423 08:03:46 @model.py:297][0m Epoch[69] Batch[100] Speed: 239.025715 samples/sec loss: 1.29687 acc: 0.69594 ce: 0.85242 lat: 3.80869 ener: 14.59016
[33mIP:142 [0m[32m[0423 08:04:39 @model.py:323][0m Start to train theta for epoch 70
[33mIP:142 [0m[32m[0423 08:05:32 @model.py:297][0m Epoch[70] Batch[100] Speed: 240.801857 samples/sec loss: 1.29550 acc: 0.69641 ce: 0.85134 lat: 3.80840 ener: 14.56005
[33mIP:142 [0m[32m[0423 08:06:22 @model.py:267][0m Change temperature from 0.33608 to 0.32129
[33mIP:142 [0m[32m[0423 08:06:22 @model.py:331][0m Start to train w for epoch 70
[33mIP:142 [0m[32m[0423 08:07:19 @model.py:297][0m Epoch[70] Batch[100] Speed: 239.306863 samples/sec loss: 1.29401 acc: 0.69691 ce: 0.85017 lat: 3.80802 ener: 14.52780
[33mIP:142 [0m[32m[0423 08:08:12 @model.py:323][0m Start to train theta for epoch 71
[33mIP:142 [0m[32m[0423 08:09:06 @model.py:297][0m Epoch[71] Batch[100] Speed: 240.511535 samples/sec loss: 1.29227 acc: 0.69750 ce: 0.84873 lat: 3.80769 ener: 14.49637
[33mIP:142 [0m[32m[0423 08:09:55 @model.py:267][0m Change temperature from 0.32129 to 0.30716
[33mIP:142 [0m[32m[0423 08:09:55 @model.py:331][0m Start to train w for epoch 71
[33mIP:142 [0m[32m[0423 08:10:53 @model.py:297][0m Epoch[71] Batch[100] Speed: 239.336835 samples/sec loss: 1.29051 acc: 0.69810 ce: 0.84726 lat: 3.80754 ener: 14.46647
[33mIP:142 [0m[32m[0423 08:11:46 @model.py:323][0m Start to train theta for epoch 72
[33mIP:142 [0m[32m[0423 08:12:39 @model.py:297][0m Epoch[72] Batch[100] Speed: 240.144883 samples/sec loss: 1.28891 acc: 0.69864 ce: 0.84595 lat: 3.80740 ener: 14.43693
[33mIP:142 [0m[32m[0423 08:13:29 @model.py:267][0m Change temperature from 0.30716 to 0.29364
[33mIP:142 [0m[32m[0423 08:13:29 @model.py:331][0m Start to train w for epoch 72
[33mIP:142 [0m[32m[0423 08:14:26 @model.py:297][0m Epoch[72] Batch[100] Speed: 239.687967 samples/sec loss: 1.28723 acc: 0.69922 ce: 0.84455 lat: 3.80722 ener: 14.40733
[33mIP:142 [0m[32m[0423 08:15:19 @model.py:323][0m Start to train theta for epoch 73
[33mIP:142 [0m[32m[0423 08:16:12 @model.py:297][0m Epoch[73] Batch[100] Speed: 240.394552 samples/sec loss: 1.28597 acc: 0.69964 ce: 0.84358 lat: 3.80704 ener: 14.37770
[33mIP:142 [0m[32m[0423 08:17:02 @model.py:267][0m Change temperature from 0.29364 to 0.28072
[33mIP:142 [0m[32m[0423 08:17:02 @model.py:331][0m Start to train w for epoch 73
[33mIP:142 [0m[32m[0423 08:17:59 @model.py:297][0m Epoch[73] Batch[100] Speed: 239.511454 samples/sec loss: 1.28447 acc: 0.70014 ce: 0.84236 lat: 3.80695 ener: 14.34848
[33mIP:142 [0m[32m[0423 08:18:52 @model.py:323][0m Start to train theta for epoch 74
[33mIP:142 [0m[32m[0423 08:19:46 @model.py:297][0m Epoch[74] Batch[100] Speed: 240.530292 samples/sec loss: 1.28281 acc: 0.70067 ce: 0.84099 lat: 3.80682 ener: 14.31970
[33mIP:142 [0m[32m[0423 08:20:35 @model.py:267][0m Change temperature from 0.28072 to 0.26837
[33mIP:142 [0m[32m[0423 08:20:35 @model.py:331][0m Start to train w for epoch 74
[33mIP:142 [0m[32m[0423 08:21:33 @model.py:297][0m Epoch[74] Batch[100] Speed: 239.273126 samples/sec loss: 1.28104 acc: 0.70126 ce: 0.83948 lat: 3.80649 ener: 14.29160
[33mIP:142 [0m[32m[0423 08:22:26 @model.py:323][0m Start to train theta for epoch 75
[33mIP:142 [0m[32m[0423 08:23:19 @model.py:297][0m Epoch[75] Batch[100] Speed: 240.308260 samples/sec loss: 1.27920 acc: 0.70187 ce: 0.83791 lat: 3.80619 ener: 14.26410
[33mIP:142 [0m[32m[0423 08:24:09 @model.py:267][0m Change temperature from 0.26837 to 0.25656
[33mIP:142 [0m[32m[0423 08:24:09 @model.py:331][0m Start to train w for epoch 75
[33mIP:142 [0m[32m[0423 08:25:06 @model.py:297][0m Epoch[75] Batch[100] Speed: 239.298902 samples/sec loss: 1.27737 acc: 0.70248 ce: 0.83635 lat: 3.80598 ener: 14.23629
[33mIP:142 [0m[32m[0423 08:25:59 @model.py:323][0m Start to train theta for epoch 76
[33mIP:142 [0m[32m[0423 08:26:53 @model.py:297][0m Epoch[76] Batch[100] Speed: 240.305847 samples/sec loss: 1.27561 acc: 0.70306 ce: 0.83487 lat: 3.80576 ener: 14.20869
[33mIP:142 [0m[32m[0423 08:27:43 @model.py:267][0m Change temperature from 0.25656 to 0.24527
[33mIP:142 [0m[32m[0423 08:27:43 @model.py:331][0m Start to train w for epoch 76
[33mIP:142 [0m[32m[0423 08:28:40 @model.py:297][0m Epoch[76] Batch[100] Speed: 239.151915 samples/sec loss: 1.27386 acc: 0.70367 ce: 0.83339 lat: 3.80549 ener: 14.18070
[33mIP:142 [0m[32m[0423 08:29:33 @model.py:323][0m Start to train theta for epoch 77
[33mIP:142 [0m[32m[0423 08:30:26 @model.py:297][0m Epoch[77] Batch[100] Speed: 240.262216 samples/sec loss: 1.27201 acc: 0.70430 ce: 0.83180 lat: 3.80523 ener: 14.15334
[33mIP:142 [0m[32m[0423 08:31:16 @model.py:267][0m Change temperature from 0.24527 to 0.23448
[33mIP:142 [0m[32m[0423 08:31:16 @model.py:331][0m Start to train w for epoch 77
[33mIP:142 [0m[32m[0423 08:32:14 @model.py:297][0m Epoch[77] Batch[100] Speed: 238.277237 samples/sec loss: 1.27008 acc: 0.70495 ce: 0.83014 lat: 3.80506 ener: 14.12695
[33mIP:142 [0m[32m[0423 08:33:07 @model.py:323][0m Start to train theta for epoch 78
[33mIP:142 [0m[32m[0423 08:34:01 @model.py:297][0m Epoch[78] Batch[100] Speed: 239.658444 samples/sec loss: 1.26838 acc: 0.70553 ce: 0.82869 lat: 3.80489 ener: 14.10074
[33mIP:142 [0m[32m[0423 08:34:50 @model.py:267][0m Change temperature from 0.23448 to 0.22416
[33mIP:142 [0m[32m[0423 08:34:50 @model.py:331][0m Start to train w for epoch 78
[33mIP:142 [0m[32m[0423 08:35:48 @model.py:297][0m Epoch[78] Batch[100] Speed: 238.698418 samples/sec loss: 1.26662 acc: 0.70613 ce: 0.82719 lat: 3.80474 ener: 14.07465
[33mIP:142 [0m[32m[0423 08:36:41 @model.py:323][0m Start to train theta for epoch 79
[33mIP:142 [0m[32m[0423 08:37:35 @model.py:297][0m Epoch[79] Batch[100] Speed: 239.814778 samples/sec loss: 1.26467 acc: 0.70678 ce: 0.82548 lat: 3.80460 ener: 14.04918
[33mIP:142 [0m[32m[0423 08:38:24 @model.py:267][0m Change temperature from 0.22416 to 0.21430
[33mIP:142 [0m[32m[0423 08:38:24 @model.py:331][0m Start to train w for epoch 79
[33mIP:142 [0m[32m[0423 08:39:21 @model.py:297][0m Epoch[79] Batch[100] Speed: 239.627893 samples/sec loss: 1.26273 acc: 0.70744 ce: 0.82378 lat: 3.80451 ener: 14.02455
[33mIP:142 [0m[32m[0423 08:40:14 @model.py:323][0m Start to train theta for epoch 80
[33mIP:142 [0m[32m[0423 08:41:08 @model.py:297][0m Epoch[80] Batch[100] Speed: 240.582165 samples/sec loss: 1.26063 acc: 0.70814 ce: 0.82192 lat: 3.80443 ener: 14.00010
[33mIP:142 [0m[32m[0423 08:41:58 @model.py:267][0m Change temperature from 0.21430 to 0.20487
[33mIP:142 [0m[32m[0423 08:41:58 @model.py:331][0m Start to train w for epoch 80
[33mIP:142 [0m[32m[0423 08:42:55 @model.py:297][0m Epoch[80] Batch[100] Speed: 239.025353 samples/sec loss: 1.25849 acc: 0.70886 ce: 0.82002 lat: 3.80436 ener: 13.97551
[33mIP:142 [0m[32m[0423 08:43:48 @model.py:323][0m Start to train theta for epoch 81
[33mIP:142 [0m[32m[0423 08:44:42 @model.py:297][0m Epoch[81] Batch[100] Speed: 239.829387 samples/sec loss: 1.25661 acc: 0.70948 ce: 0.81838 lat: 3.80429 ener: 13.95111
[33mIP:142 [0m[32m[0423 08:45:32 @model.py:267][0m Change temperature from 0.20487 to 0.19586
[33mIP:142 [0m[32m[0423 08:45:32 @model.py:331][0m Start to train w for epoch 81
[33mIP:142 [0m[32m[0423 08:46:29 @model.py:297][0m Epoch[81] Batch[100] Speed: 238.414069 samples/sec loss: 1.25473 acc: 0.71011 ce: 0.81673 lat: 3.80418 ener: 13.92695
[33mIP:142 [0m[32m[0423 08:47:22 @model.py:323][0m Start to train theta for epoch 82
[33mIP:142 [0m[32m[0423 08:48:16 @model.py:297][0m Epoch[82] Batch[100] Speed: 240.044840 samples/sec loss: 1.25265 acc: 0.71081 ce: 0.81489 lat: 3.80406 ener: 13.90312
[33mIP:142 [0m[32m[0423 08:49:05 @model.py:267][0m Change temperature from 0.19586 to 0.18724
[33mIP:142 [0m[32m[0423 08:49:05 @model.py:331][0m Start to train w for epoch 82
[33mIP:142 [0m[32m[0423 08:50:03 @model.py:297][0m Epoch[82] Batch[100] Speed: 239.573282 samples/sec loss: 1.25057 acc: 0.71151 ce: 0.81303 lat: 3.80396 ener: 13.87975
[33mIP:142 [0m[32m[0423 08:50:56 @model.py:323][0m Start to train theta for epoch 83
[33mIP:142 [0m[32m[0423 08:51:49 @model.py:297][0m Epoch[83] Batch[100] Speed: 240.368689 samples/sec loss: 1.24854 acc: 0.71218 ce: 0.81124 lat: 3.80385 ener: 13.85668
[33mIP:142 [0m[32m[0423 08:52:39 @model.py:267][0m Change temperature from 0.18724 to 0.17900
[33mIP:142 [0m[32m[0423 08:52:39 @model.py:331][0m Start to train w for epoch 83
[33mIP:142 [0m[32m[0423 08:53:36 @model.py:297][0m Epoch[83] Batch[100] Speed: 239.429671 samples/sec loss: 1.24646 acc: 0.71286 ce: 0.80938 lat: 3.80373 ener: 13.83386
[33mIP:142 [0m[32m[0423 08:54:29 @model.py:323][0m Start to train theta for epoch 84
[33mIP:142 [0m[32m[0423 08:55:23 @model.py:297][0m Epoch[84] Batch[100] Speed: 240.089570 samples/sec loss: 1.24428 acc: 0.71360 ce: 0.80741 lat: 3.80361 ener: 13.81125
[33mIP:142 [0m[32m[0423 08:56:12 @model.py:267][0m Change temperature from 0.17900 to 0.17112
[33mIP:142 [0m[32m[0423 08:56:12 @model.py:331][0m Start to train w for epoch 84
[33mIP:142 [0m[32m[0423 08:57:10 @model.py:297][0m Epoch[84] Batch[100] Speed: 238.883234 samples/sec loss: 1.24202 acc: 0.71436 ce: 0.80538 lat: 3.80353 ener: 13.78886
[33mIP:142 [0m[32m[0423 08:58:03 @model.py:323][0m Start to train theta for epoch 85
[33mIP:142 [0m[32m[0423 08:58:56 @model.py:297][0m Epoch[85] Batch[100] Speed: 240.047221 samples/sec loss: 1.23981 acc: 0.71510 ce: 0.80339 lat: 3.80346 ener: 13.76677
[33mIP:142 [0m[32m[0423 08:59:46 @model.py:267][0m Change temperature from 0.17112 to 0.16359
[33mIP:142 [0m[32m[0423 08:59:46 @model.py:331][0m Start to train w for epoch 85
[33mIP:142 [0m[32m[0423 09:00:44 @model.py:297][0m Epoch[85] Batch[100] Speed: 239.007634 samples/sec loss: 1.23754 acc: 0.71587 ce: 0.80132 lat: 3.80339 ener: 13.74493
[33mIP:142 [0m[32m[0423 09:01:37 @model.py:323][0m Start to train theta for epoch 86
[33mIP:142 [0m[32m[0423 09:02:30 @model.py:297][0m Epoch[86] Batch[100] Speed: 240.085207 samples/sec loss: 1.23538 acc: 0.71659 ce: 0.79938 lat: 3.80331 ener: 13.72316
[33mIP:142 [0m[32m[0423 09:03:20 @model.py:267][0m Change temperature from 0.16359 to 0.15640
[33mIP:142 [0m[32m[0423 09:03:20 @model.py:331][0m Start to train w for epoch 86
[33mIP:142 [0m[32m[0423 09:04:18 @model.py:297][0m Epoch[86] Batch[100] Speed: 237.708488 samples/sec loss: 1.23316 acc: 0.71733 ce: 0.79737 lat: 3.80321 ener: 13.70162
[33mIP:142 [0m[32m[0423 09:05:11 @model.py:323][0m Start to train theta for epoch 87
[33mIP:142 [0m[32m[0423 09:06:05 @model.py:297][0m Epoch[87] Batch[100] Speed: 240.115376 samples/sec loss: 1.23094 acc: 0.71806 ce: 0.79536 lat: 3.80311 ener: 13.68036
[33mIP:142 [0m[32m[0423 09:06:54 @model.py:267][0m Change temperature from 0.15640 to 0.14952
[33mIP:142 [0m[32m[0423 09:06:54 @model.py:331][0m Start to train w for epoch 87
[33mIP:142 [0m[32m[0423 09:07:51 @model.py:297][0m Epoch[87] Batch[100] Speed: 239.389242 samples/sec loss: 1.22867 acc: 0.71883 ce: 0.79329 lat: 3.80304 ener: 13.65945
[33mIP:142 [0m[32m[0423 09:08:44 @model.py:323][0m Start to train theta for epoch 88
[33mIP:142 [0m[32m[0423 09:09:38 @model.py:297][0m Epoch[88] Batch[100] Speed: 240.135450 samples/sec loss: 1.22641 acc: 0.71958 ce: 0.79124 lat: 3.80298 ener: 13.63880
[33mIP:142 [0m[32m[0423 09:10:28 @model.py:267][0m Change temperature from 0.14952 to 0.14294
[33mIP:142 [0m[32m[0423 09:10:28 @model.py:331][0m Start to train w for epoch 88
[33mIP:142 [0m[32m[0423 09:11:25 @model.py:297][0m Epoch[88] Batch[100] Speed: 239.398440 samples/sec loss: 1.22409 acc: 0.72034 ce: 0.78912 lat: 3.80297 ener: 13.61834
[33mIP:142 [0m[32m[0423 09:12:18 @model.py:323][0m Start to train theta for epoch 89
[33mIP:142 [0m[32m[0423 09:13:11 @model.py:297][0m Epoch[89] Batch[100] Speed: 240.650772 samples/sec loss: 1.22174 acc: 0.72111 ce: 0.78697 lat: 3.80296 ener: 13.59832
[33mIP:142 [0m[32m[0423 09:14:01 @model.py:267][0m Change temperature from 0.14294 to 0.13665
[33mIP:142 [0m[32m[0423 09:14:01 @model.py:331][0m Start to train w for epoch 89
[33mIP:142 [0m[32m[0423 09:14:58 @model.py:297][0m Epoch[89] Batch[100] Speed: 239.209393 samples/sec loss: 1.21934 acc: 0.72191 ce: 0.78476 lat: 3.80295 ener: 13.57855
